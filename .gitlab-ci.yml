stages:
  - test
  - build
  - deploy

variables:
  POSTGRES_HOST: postgres
  POSTGRES_DB: postgres
  POSTGRES_USER: postgres
  POSTGRES_PASSWORD: ""
  SAMPLEDB_SQLALCHEMY_DATABASE_URI: "postgresql+psycopg2://postgres:@postgres:5432/postgres"
  POSTGRES_HOST_AUTH_METHOD: trust

test:
  stage: test
  image: debian:11
  services:
    - postgres:12
  tags:
    - kubernetes-executor
  script:
    - apt-get update
    # set up Python 3
    - DEBIAN_FRONTEND=noninteractive apt-get install -y git python3-pip postgresql-client chromium libpangocairo-1.0-0 gettext
    - mkdir ${CI_PROJECT_DIR}/test_files/
    - for i in 0 1 2 3; do
        psql -h "postgres" -U "$POSTGRES_USER" -d "$POSTGRES_DB" -c "CREATE DATABASE testdb_$i;";
        mkdir ${CI_PROJECT_DIR}/test_files/$i/;
      done
    # install dependencies
    - python3 -m pip install -r requirements.txt
    # build translations once instead of with each test
    - python3 -m sampledb build_translations
    # set up configuration values for testing
    - export SAMPLEDB_FILE_STORAGE_PATH=${CI_PROJECT_DIR}/test_files/
    - export SAMPLEDB_BUILD_TRANSLATIONS=
    # run tests and gather coverage data
    - python3 -m pytest -x -s -n=4 --cov=sampledb/ --junitxml=pytest.xml tests
  artifacts:
    reports:
      junit: pytest.xml

analyze:
  stage: test
  image: ubuntu:20.04
  script:
    - apt-get update
    # set up Python 3
    - apt-get install -y git python3-pip
    # install static analysis packages
    - python3 -m pip install pycodestyle pyflakes
    - python3 -m pycodestyle --ignore=E402,E501,W504,W601 sampledb
    - python3 -m pyflakes sampledb

documentation:
  stage: test
  image: debian:11
  services:
    - postgres:latest
  tags:
    - kubernetes-executor
  script:
    - apt-get update
    # set up Python 3
    - apt-get install -y git python3-pip libpython3-dev chromium libpangocairo-1.0-0 gettext
    # install dependencies
    - python3 -m pip install -r requirements.txt
    # generate documentation images using current version
    - python3 docs/utils/generate_images.py
    # build documentation
    - python3 -m sphinx -b html -t iffSamples docs/ build_documentation/
  artifacts:
    paths:
    - build_documentation

build:
  stage: build
  image: docker:stable
  tags:
    - privileged-executor
  script:
    - apk add git
    - export VERSION=`git describe`
    - docker build --build-arg SAMPLEDB_VERSION="$VERSION" -t $CI_REGISTRY_IMAGE:$CI_COMMIT_SHA .
    - docker login -u gitlab-ci-token -p $CI_JOB_TOKEN $CI_REGISTRY
    - docker push $CI_REGISTRY_IMAGE:$CI_COMMIT_SHA
    - if echo "$CI_COMMIT_TAG" | grep -Eq '^v[0-9]+\.[0-9]+\.[0-9]+$'; then
        export VERSION=`echo "$CI_COMMIT_TAG" | sed 's/^v//'`;
        docker tag $CI_REGISTRY_IMAGE:$CI_COMMIT_SHA $CI_REGISTRY_IMAGE:$VERSION;
        docker push $CI_REGISTRY_IMAGE:$VERSION;
      fi

pages:
  stage: deploy
  image: ubuntu:20.04
  only:
    - master
    - tags
    - develop
  script:
    - mv build_documentation public
  artifacts:
    paths:
    - public
    expire_in: 1 day

deploy-to-dev:
  stage: deploy
  image: ubuntu:20.04
  environment: staging
  only:
    - develop@Scientific-IT-Systems/SampleDB
  script:
    - apt-get update
    - apt-get install -y ssh
    # set up SSH for access to deployment server
    - mkdir -p --mode=700 ~/.ssh/
    - echo "$DEPLOYMENT_PRIVATE_KEY" > ~/.ssh/deployment_key
    - chmod 400 ~/.ssh/deployment_key
    - echo "$SSH_SERVER_HOSTKEYS" > ~/.ssh/known_hosts
    - chmod 400 ~/.ssh/known_hosts
    # actual deployment is handled via authorized_keys command
    - ssh -i ~/.ssh/deployment_key iffregistry@iffweb.iff.kfa-juelich.de "$CI_COMMIT_SHA"

deploy-to-github:
  stage: deploy
  image: ubuntu:20.04
  variables:
    GIT_STRATEGY: none
  only:
    - branches@Scientific-IT-Systems/SampleDB
    - tags@Scientific-IT-Systems/SampleDB
  script:
    - apt-get update
    - apt-get install -y git
    - mkdir --mode=700 ~/.ssh/
    - echo "$SCIAPP_SAMPLEDB_PRIVATE_KEY" > ~/.ssh/id_rsa
    - echo "github.com $GITHUB_HOST_KEY" >> ~/.ssh/known_hosts
    - chmod 400 ~/.ssh/*
    - git clone --mirror "$CI_REPOSITORY_URL" repo
    - cd repo && git push --mirror git@github.com:sciapp/sampledb.git && cd -

deploy-to-dockerhub:
  stage: deploy
  image: docker:stable
  tags:
    - privileged-executor
  only:
    - tags@Scientific-IT-Systems/SampleDB
    - develop@Scientific-IT-Systems/SampleDB
  script:
  - docker login -u gitlab-ci-token -p $CI_JOB_TOKEN $CI_REGISTRY
  - docker pull $CI_REGISTRY_IMAGE:$CI_COMMIT_SHA
  - cat $DOCKERHUB_PASSWORD_FILE | docker login --username $DOCKERHUB_USERNAME --password-stdin
  - if [ "$CI_COMMIT_REF_NAME" = "develop" ]; then
      docker tag $CI_REGISTRY_IMAGE:$CI_COMMIT_SHA sciapp/sampledb:develop;
      docker push sciapp/sampledb:develop;
    fi
  - if echo "$CI_COMMIT_TAG" | grep -Eq '^v[0-9]+\.[0-9]+\.[0-9]+$'; then
      export VERSION=`echo "$CI_COMMIT_TAG" | sed 's/^v//'`;
      docker tag $CI_REGISTRY_IMAGE:$CI_COMMIT_SHA sciapp/sampledb:$VERSION;
      docker push sciapp/sampledb:$VERSION;
      docker tag sciapp/sampledb:$VERSION sciapp/sampledb:latest;
      docker push sciapp/sampledb:latest;
    fi

deploy-to-pypi:
  stage: deploy
  image: python:3
  only:
    - tags@Scientific-IT-Systems/SampleDB
  script:
    - python3 -m pip install setuptools wheel twine
    - python3 setup.py sdist
    - if echo "$CI_COMMIT_TAG" | grep -Eq '^v[0-9]+\.[0-9]+\.[0-9]+$'; then
        export VERSION=`echo "$CI_COMMIT_TAG" | sed 's/^v//'`;
        python3 -m twine upload dist/sampledb-$VERSION.tar.gz;
      fi
